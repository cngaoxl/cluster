# 10大聚类算法
* 亲和力传播
* 聚合聚类
* BIRCH
* DBSCAN
* K-均值
* Mini-Batch K-均值
* Mean Shift
* OPTICS
* 光谱聚类
* 高斯混合
* KMeans
  
# 五大原则判断是否要用Clustering
* https://www.dataapplab.com/when-clustering-doesnt-make-sense/
## 数据是否已有潜在的类别标签？
在数据中使用现有的类标签通常比尝试Clustering为数据创建新标签更好。 如果你有选择权，有监督的Machine Learning几乎总是优于分类任务中的无监督学习。

如果你有数据但是无法将数据组织成有意义的组，那么Clustering便是有意义的。 但如果你的数据集中已有直观的类标签，则Clustering创建的标签可能无法与原始类标签相媲美。

## 数据是Categorical还是Continuous的？
许多Clustering算法（如DBSCAN或K-Means）使用距离来计算观测值之间的相似性。 因此，某些聚类算法在Continuous变量下表现更好。但是，如果你有Categorical数据，则可以对属性进行One-hot编码或使用为Categorical数据构建的Clustering算法，例如K-Modes。 应该注意的是，计算二进制变量之间的距离并没有多大意义。

了解不同的Clustering算法如何在不同的数据类型上执行，对于是否对数据使用Clustering方法至关重要。

## 数据是什么样的？
如果可视化数据没有明显的分离或形成不同的组，则Clustering可能不合适。

## 有办法验证你的Clustering算法吗？
为了信任聚类算法结果，你必须有一种方法来衡量算法的结果。 可以使用内部或外部验证指标验证Clustering的算法性能。

内部验证的一个例子是Silhouette评分，一种衡量每个观测值被聚类程度的方法。Silhouette图显示了Clusters的相对大小，平均Silhouette得分以及观测值是否被不正确地Clustered。 下图中的红线表示六个Clusters的平均Silhouette得分：约为0.45（1表示完美，0.45表示不是很好）。

##  Clustering是否提供了对数据任何新的总结？
假设满足以上所有考虑因素：拥有没有类别标签的连续数据，可视化数据并且存在一些分离，选择了对你的分析有意义的验证度量标准。你对数据运行Clustering算法并获得相当高的Silhouette分数。但是还不够，在执行Clustering分析之后，检查各个聚类中的观测值至关重要。 这一步评估Clusters是否提供对数据的任何新的总结。算法是否真的找到了相似的观测值并最大化了类内相似性，同时最小化了Cluster的相似性？

检查Clusters的一种简单方法是计算每个Clusters中观察值的简单统计量，例如均值。